{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Spam Filtering Engine using Spark MlLib\n",
    "\n",
    "SOURCE:\n",
    "````     \n",
    "     https://acadgild.com/blog/building-spam-filtering-engine-using-spark-mllib\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Spam Filtering?\n",
    "* Spam filtering is the process of detecting the unwanted or unsolicited \n",
    "  email or text from getting into the user’s inbox. \n",
    "* Spam filtering applications work on text filters. \n",
    "* Text filters work by using algorithms to detect which words \n",
    "  and phrases are most often used in the spam emails.\n",
    "\n",
    "* Now, let us build a spam filtering application using logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "# $ pwd\n",
    "# /Users/mparsian/work_in_progress/data/emails\n",
    "\n",
    "# $ ls -1\n",
    "# query.txt\n",
    "# training_emails_nospam.txt (normal emails, which are NOT spam)\n",
    "# training_emails_spam.txt (spam emails)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.93:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10c6dc550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check SparkSession\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_mails = spark.sparkContext.textFile('data/emails/training_emails_spam.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_mails.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Samsung Galaxy End of YearPromo You have 1 week remaining to retrieve your won prize for the Samsung Galaxy Xmas Promo 'C' draw category winning prize of Seven Hundred and Fifty Thousand Euros each and a Samsung Galaxy S6 EDGE. Winning Ticket Number:WIN-707-COS.  We advise you to keep this winning notification confidential and away from public notice to avoid double claim/mistransfer or impersonation until after remittance/payment to you.\",\n",
       " \"We've picked out 10 new matches for you. Meet them now and then check out all the singles in your area! you might win a prize too\",\n",
       " 'For claim fill in the attached claim application form completely and follow instructions carefully.',\n",
       " 'Dear sir, I am a Prince in a far kingdom you have not heard of.  I want to send you money via wire transfer so please ...',\n",
       " 'Get Viagra real cheap!  Send money right away to ...',\n",
       " 'Oh my gosh you can be really strong too with these drugs found in the rainforest. Get them cheap right now ...',\n",
       " 'YOUR COMPUTER HAS BEEN INFECTED!  YOU MUST RESET YOUR PASSWORD.  Reply to this email with your password and SSN ...',\n",
       " 'THIS IS NOT A SCAM!  Send money and get access to awesome stuff really cheap and never have to ...',\n",
       " 'Dear Good Friend, This message might come to you as a surprise. However, it all just my urgent needs for a foreign partner that made me to contact you for this transaction.  I have the opportunity of transferring the left over funds ($15 million dollars) of one of my bank clients who died along with his entire family on Monday 31st July 2004 in a plane crash. I am inviting you for a business deal where this money can be shared between us in the ratio of 60 / 40% if you agree to my business proposal. Further details of the transfer will be forwarded to you as soon as I receive your responses. Please indicate your willingness by sending the below is information for more clarification and easy communication.',\n",
       " \"Greetings, I am Idrissa Nassa, i know that you will be surprise to hear about this business since we don't know each other before, but it was due to the urgency of this business makes me to contact you immediately through email please accept my apology. I am the manager of (C.B.I) Coris Bank International Ouagadougou Burkina Faso. i need your urgent assistance in transferring this sum of (forty million five hundred thousand United States dollars) to a foreign account, please would you be interested to assist me in this transaction with your bank account to receive this fund.\",\n",
       " \"Did you miss some freebies recently? Don't worry! We put together a collection of the top new freebies available right now. Make sure you claimed all of them - some samples are expiring soon. Claim yours while they are still available!\",\n",
       " \"We are pleased to announce you we have found unclaimed money for your familly: Claim it Now. You have until 4 November, 12 AM tonight to claim it or it will be reallocated to someone else.  We don't have the exact number we own you but you can verify here. \",\n",
       " 'HELLO MY DEAR, I am writing this mail to you with tears and sorrow from my heart. With due respect trust and humanity, I appeal to you to exercise a little patience and read through my letter, I wish to contact you personally for a long term business relationship and investment assistance in your Country so I feel quite safe dealing with you in this important business having gone through your remarkable profile, honestly I am writing this email to you with pains, tears and sorrow from my heart, I will really like to have a good relationship with you and I have a special reason why I decided to contact you, I decided to contact you due to the urgency of my situation, My name is Miss Samira Kipkalya Kones, 23yrs old female and I held from Kenya in East Africa. My father was the former Kenyan road Minister. He and Assistant Minister of Home Affairs Lorna Laboso had been on board the Cessna 210, which was headed to Kericho and crashed in a remote area called Kajong, in western Kenya. The plane crashed on the Tuesday 10th, June, 2008. You can read more about the crash through the below site:',\n",
       " 'AWAITING YOUR URGENT AND POSITIVE RESPONSE, Please do keep this only to your self for now un till the bank will transfer the fund. I plead to you not to disclose it till I come over because I am afraid of my wicked stepmother who has threatened to kill me and have the money alone, I thank God Today that am out from my country (KENYA) but now In (Burkina Faso) where my father deposited these money with my name as the next of Kin. I have the documents for the claims.',\n",
       " '\\u200cMeet Plus-Sized Singles Near You, and provide your email, bank account, social security numbers, bank accounts ao that I can deposit 5M. One faithful morning, I opened my father’s briefcase and found out the documents which he has deposited huge amount of money in one bank in Burkina Faso with my name as the next of kin. I traveled to Burkina Faso to withdraw the money for a better life so that I can take care of myself and start a new life, on my arrival, the Bank Director whom I met in person told me that my father’s instruction/will to the bank is that the money would only be release to me when I am married or present a trustee who will help me and invest the money overseas. I am in search of an honest and reliable person who will help me and stand as my trustee so that I will present him to the Bank for transfer of the money to his bank account overseas. I have chosen to contact you after my prayers and I believe that you will not betray my trust. But rather take me as your own sister or daughter.',\n",
       " 'Get Viagra and drugs very fast and real cheap!  Send money right away to my bank account in Nigeria',\n",
       " 'Get real money fast: With my position in the office i assure you with 100% risk free that this transaction is not a childish game play and i want you to indicate your full interest with assurance of trust that you will not betray me once the fund is transfer into your nominated bank account, while i look forward for your urgent reply.',\n",
       " 'Our new\\u2002survey\\u2004could\\u2005help you slash\\u2004your energy\\u2005bills without any risk, believe it it works, just call us at 800-555-5555',\n",
       " \"Greetings, I am Mr. Nassa, i know that you will be surprise to hear about this business since we don't know each other before, but it was due to the urgency of this business makes me to contact you immediately through email please accept my apology. I am the manager of (C.B.I) Coris Bank International Ouagadougou Burkina Faso. i need your urgent assistance in transferring this sum of (forty million five hundred thousand United States dollars) to a foreign account, please would you be interested to assist me in this transaction with your bank account to receive this fund.\",\n",
       " 'Do you wanty to make an additional $5000 per month by flipping houses in the bay area? call me to show you how it is done! it works, believe it.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_mails.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Samsung Galaxy End of YearPromo You have 1 week remaining to retrieve your won prize for the Samsung Galaxy Xmas Promo 'C' draw category winning prize of Seven Hundred and Fifty Thousand Euros each and a Samsung Galaxy S6 EDGE. Winning Ticket Number:WIN-707-COS.  We advise you to keep this winning notification confidential and away from public notice to avoid double claim/mistransfer or impersonation until after remittance/payment to you.\",\n",
       " \"We've picked out 10 new matches for you. Meet them now and then check out all the singles in your area! you might win a prize too\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_mails.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-spam emails:\n",
    "ham_mails = spark.sparkContext.textFile('data/emails/training_emails_nospam.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_mails.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dear Spark Learner, Thanks so much for attending the Spark Summit 2014!  Check out videos of talks from the summit at ...',\n",
       " 'Hi Mom, Apologies for being late about emailing and forgetting to send you the package.  I hope you and bro have been ...',\n",
       " 'Wow, hey Fred, just heard about the Spark petabyte sort.  I think we need to take time to try it out immediately ...']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_mails.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In machine learning, feature hashing, also known as the hashing trick, \n",
    "# is a fast and space-efficient way of vectorizing features, i.e. turning \n",
    "# arbitrary features into indices in a vector or matrix. It works by applying \n",
    "# a hash function to the features and using their hash values as indices directly, \n",
    "# rather than looking the indices up in an associative array.\n",
    "\n",
    "# This can be done as follows\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "\n",
    "# Maps a sequence of terms to their term frequencies using the hashing trick.\n",
    "features = HashingTF(numFeatures = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.mllib.feature.HashingTF at 0x10c7e2ac8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create feature vectors by converting the text into bigrams of characters \n",
    "# using n-gram model and hashing them to a length 1000 feature vector that can be \n",
    "# passed into a Mllib application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to map these features with our datasets. \n",
    "# This can be done as follows\n",
    "\n",
    "features_spam = spam_mails.map(lambda mail : features.transform(mail.split(\" \")))\n",
    "features_ham = ham_mails.map(lambda mail : features.transform(mail.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[8] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_spam.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseVector(1000, {0: 1.0, 9: 1.0, 28: 3.0, 31: 3.0, 34: 1.0, 69: 1.0, 70: 2.0, 80: 2.0, 94: 1.0, 101: 3.0, 147: 1.0, 155: 1.0, 169: 2.0, 174: 1.0, 184: 1.0, 216: 1.0, 224: 1.0, 240: 2.0, 241: 1.0, 242: 1.0, 268: 1.0, 289: 1.0, 300: 1.0, 301: 1.0, 314: 1.0, 317: 1.0, 321: 1.0, 350: 1.0, 365: 4.0, 437: 1.0, 484: 1.0, 589: 1.0, 590: 1.0, 599: 1.0, 614: 1.0, 733: 1.0, 759: 1.0, 772: 1.0, 778: 1.0, 787: 1.0, 798: 1.0, 799: 1.0, 821: 1.0, 827: 1.0, 864: 1.0, 882: 1.0, 887: 1.0, 903: 1.0, 912: 1.0, 919: 1.0, 922: 1.0, 925: 2.0, 932: 1.0, 940: 1.0, 941: 1.0})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_spam.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[11] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ham.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseVector(1000, {0: 1.0, 6: 1.0, 69: 1.0, 80: 1.0, 150: 1.0, 161: 1.0, 162: 2.0, 317: 2.0, 370: 1.0, 403: 1.0, 423: 1.0, 521: 1.0, 604: 1.0, 651: 1.0, 743: 1.0, 770: 1.0, 809: 1.0, 827: 1.0, 831: 1.0, 872: 1.0, 971: 1.0})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ham.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam filtering is a kind of supervised learning\n",
    "## Create Labels for spam and non-spam emails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As spam filtering is a kind of supervised learning, \n",
    "# we need to provide labeled data to the application. \n",
    "# Labeled data typically consists of a bag of multidimensional \n",
    "# feature vectors. A labeled point is a local vector, \n",
    "# either dense or sparse, associated with a label/response. \n",
    "# In MLlib, labeled points are used in supervised learning algorithms. \n",
    "# We use a double to store a label, so we can use labeled points in \n",
    "# both regression and classification.\n",
    "\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "positive_data = features_spam.map(lambda features : LabeledPoint(1, features))\n",
    "negative_data = features_ham.map(lambda features :  LabeledPoint(0, features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, (1000,[0,9,28,31,34,69,70,80,94,101,147,155,169,174,184,216,224,240,241,242,268,289,300,301,314,317,321,350,365,437,484,589,590,599,614,733,759,772,778,787,798,799,821,827,864,882,887,903,912,919,922,925,932,940,941],[1.0,1.0,3.0,3.0,1.0,1.0,2.0,2.0,1.0,3.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,4.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0]))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, (1000,[0,6,69,80,150,161,162,317,370,403,423,521,604,651,743,770,809,827,831,872,971],[1.0,1.0,1.0,1.0,1.0,1.0,2.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_data.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we need to create the training data for our application, \n",
    "# training data will be the 60% of total data. So first we will \n",
    "# club both the spam and ham datasets and then we will create the \n",
    "# training and test data as follows.\n",
    "\n",
    "data = positive_data.union(negative_data)\n",
    "data.cache()\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = data.randomSplit([0.6, 0.4], seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s create a logistic regression learner which uses the LBFGS optimizer.\n",
    "\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "logistic_learner = LogisticRegressionWithSGD()\n",
    "\n",
    "# We need to run the model using the training data.\n",
    "\n",
    "model = logistic_learner.train(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the built model\n",
    "# Next, we need to test the model by creating a prediction label.\n",
    "\n",
    "prediction_label = test.map(lambda x : (model.predict(x.features),x.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_label.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1.0),\n",
       " (1, 1.0),\n",
       " (0, 1.0),\n",
       " (1, 1.0),\n",
       " (0, 1.0),\n",
       " (0, 1.0),\n",
       " (0, 1.0),\n",
       " (1, 1.0),\n",
       " (1, 1.0),\n",
       " (0, 0.0),\n",
       " (0, 0.0),\n",
       " (0, 0.0),\n",
       " (0, 0.0),\n",
       " (0, 0.0),\n",
       " (0, 0.0),\n",
       " (0, 0.0),\n",
       " (0, 0.0)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_label.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Accuracy of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5652173913043478"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the accuracy of the model. \n",
    "# Accuracy can be calculated by taking \n",
    "# the matching terms from both the training \n",
    "# and test data. This can be done as follows:\n",
    "\n",
    "accuracy = 1.0 * prediction_label.filter(lambda x : x[0] == x[1]).count() / training.count()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In machine learning, naïve Bayes classifiers are a \n",
    "# family of simple \"probabilistic classifiers\" based on \n",
    "# applying Bayes' theorem with strong independence \n",
    "# assumptions between the features. They are among \n",
    "# the simplest Bayesian network models.\n",
    "\n",
    "from pyspark.mllib.classification import NaiveBayes\n",
    "model = NaiveBayes.train(training, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.mllib.classification.NaiveBayesModel at 0x10d1e3c88>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_label = test.map(lambda x : (model.predict(x.features),x.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 1.0),\n",
       " (1.0, 1.0),\n",
       " (1.0, 1.0),\n",
       " (1.0, 1.0),\n",
       " (0.0, 1.0),\n",
       " (1.0, 1.0),\n",
       " (1.0, 1.0),\n",
       " (1.0, 1.0),\n",
       " (1.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (1.0, 0.0),\n",
       " (1.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (1.0, 0.0),\n",
       " (0.0, 0.0)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_label.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
