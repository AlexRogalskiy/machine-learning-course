### Underfitting and Overfitting

* A model that generalizes well is a model 
  that is neither underfit nor overfit.

<img src="./over_and_under_fitting.png" alt="over_and_under_fitting">

* Generalization and overfitting

```
	• Generalization: A classifier or a regression 
	  algorithm learns to correctly predict output 
	  from given inputs not only in previously seen 
	  samples but also in previously unseen samples.

	• Overfitting: A classifier or a regression 
	  algorithm learns to correctly predict output 
	  from given inputs in previously seen samples 
	  but fails to do so in previously unseen samples.

	• Overfitting => Poor generalization.
````

* Underfitting

````
    Underfitting occurs when a model can’t accurately 
    capture the dependencies among data, usually as a 
    consequence of its own simplicity. It often yields 
    a low 𝑅² with known data and bad generalization 
    capabilities when applied with new data.
````

* Overfitting

````
    Overfitting  happens  when a  model learns both 
    dependencies  among  data  and random fluctuations. 
    In other words, a model learns the existing data 
    too well. Complex models, which have many features 
    or terms, are  often  prone  to overfitting. When 
    applied to known data, such models usually yield 
    high 𝑅². However, they  often  don’t  generalize  
    well  and  have significantly lower 𝑅² when used 
    with new data.
````

* [What Are Overfitting and Underfitting in Machine Learning?](https://towardsdatascience.com/what-are-overfitting-and-underfitting-in-machine-learning-a96b30864690)

* [Overfitting and Underfitting in Machine Learning - video 17 minutes](https://www.youtube.com/watch?v=j9_yzC-x-js)

